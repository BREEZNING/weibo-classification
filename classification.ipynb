{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import sklearn.naive_bayes\r\n",
    "from sklearn.svm import SVC\r\n",
    "import xgboost as xgb\r\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\r\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function of get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result of word segmentation\r\n",
    "def get_data(file):\r\n",
    "    from process import getting_data, getting_words\r\n",
    "    tj = getting_words(filename = file)\r\n",
    "    seg, index = getting_data(file, tj)\r\n",
    "    df = pd.read_excel(file)\r\n",
    "    y = df['class'].values\r\n",
    "    y = np.delete(y, index)\r\n",
    "    return seg, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function of tf-idf transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tf-idf weight\r\n",
    "def data_process(seg):\r\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\r\n",
    "    # transform the data structure of word segmentation \r\n",
    "    corpus = []\r\n",
    "    for text in seg:\r\n",
    "        corpus.append(' '.join(text))\r\n",
    "\r\n",
    "    # convert the collection of words to a matrix of token counts, a[i][j] means the counts of word j in text i\r\n",
    "    tf_vectorizer = CountVectorizer()\r\n",
    "    \r\n",
    "    # fit_transform turn the texts into text-word matrix\r\n",
    "    tf_matrix = tf_vectorizer.fit_transform(corpus)\r\n",
    "    \r\n",
    "    # transform the matrix to a normalized tf-idf representation \r\n",
    "    tfidf_transformer = TfidfTransformer()\r\n",
    "    \r\n",
    "    # compute the tf-idf matrix\r\n",
    "    tfidf_matrix = tfidf_transformer.fit_transform(tf_matrix)\r\n",
    "    \r\n",
    "    # get all words\r\n",
    "    word_list = tf_vectorizer.get_feature_names_out()\r\n",
    "    \r\n",
    "    # get the tf-idf weight of each word in all text, a[i][j] means the tf-idf weight of word j in text i\r\n",
    "    tfidf_weight = tfidf_matrix.toarray()\r\n",
    "\r\n",
    "    return word_list, tfidf_weight, tfidf_matrix, tf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\r\n",
    "def split_data(X,y,test_per = 0.2):\r\n",
    "    from sklearn.model_selection import train_test_split\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_per, random_state=42)\r\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([['深圳', '疫情', '深圳'],\n  ['深圳', '疫情', '提醒'],\n  ['第一', '国家', '物质', '深圳', '疫情'],\n  ['躲避', '深圳', '疫情', '结果', '自己', '上头', '市里'],\n  ['深圳', '疫情', '停职', '绝望']],\n array([0, 0, 0, 1, 1], dtype=int64))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg, y = get_data('weibo_test.xlsx')\r\n",
    "seg[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list, X, tfidf_matrix, tf_vectorizer = data_process(seg)\r\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\r\n",
    "X_train[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVM and Gradient Boosting have the lowest testing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit GaussianNB\r\n",
    "def GNB(X_train, X_test, y_train, y_test):\r\n",
    "    gnb = sklearn.naive_bayes.GaussianNB()\r\n",
    "    gnb.fit(X_train, y_train)\r\n",
    "    y_pred = gnb.predict(X_test)\r\n",
    "    score_train = gnb.score(X_train, y_train)\r\n",
    "    score_test = gnb.score(X_test, y_test)\r\n",
    "\r\n",
    "    return score_train,score_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit CategoricalNB\r\n",
    "def CNB(X_train, X_test, y_train, y_test):\r\n",
    "    cnb = sklearn.naive_bayes.CategoricalNB()\r\n",
    "    cnb.fit(X_train, y_train)\r\n",
    "    y_pred = cnb.predict(X_test)\r\n",
    "    score_train = cnb.score(X_train, y_train)\r\n",
    "    score_test = cnb.score(X_test, y_test)\r\n",
    "\r\n",
    "    return score_train,score_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit MultinomiaNB\r\n",
    "def MNB(X_train, X_test, y_train, y_test):\r\n",
    "    mnb = sklearn.naive_bayes.MultinomialNB()\r\n",
    "    mnb.fit(X_train, y_train)\r\n",
    "    y_pred = mnb.predict(X_test)\r\n",
    "    score_train = mnb.score(X_train, y_train)\r\n",
    "    score_test = mnb.score(X_test, y_test)\r\n",
    "\r\n",
    "    return score_train,score_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different kernel\r\n",
    "def SVM(X_train, X_test, y_train, y_test, k='rbf', c=None):\r\n",
    "    svm = SVC(kernel=k, class_weight=c)\r\n",
    "    svm.fit(X_train, y_train)\r\n",
    "    y_pred = svm.predict(X_test)\r\n",
    "    score_train = svm.score(X_train, y_train)\r\n",
    "    score_test = svm.score(X_test, y_test)\r\n",
    "    return score_train, score_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\r\n",
    "def XGB(X_train, X_test, y_train, y_test):\r\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\r\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\r\n",
    "    xgb_one = xgb.XGBClassifier(learning_rate=0.5, n_estimators=10, random_state=0)\r\n",
    "    xgb_one.fit(X_train, y_train)\r\n",
    "    pred = xgb_one.predict(X_test)\r\n",
    "    return pred\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\r\n",
    "def ada(X_train, X_test, y_train, y_test):\r\n",
    "    mod = AdaBoostClassifier(random_state=0)\r\n",
    "    mod.fit(X_train, y_train)\r\n",
    "    pred = mod.predict(X_test)\r\n",
    "    score = mod.score(X_test, y_test)\r\n",
    "    return pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\r\n",
    "def gb(X_train, X_test, y_train, y_test):\r\n",
    "    mod = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2, random_state=0)\r\n",
    "    scores = cross_validate(mod, X_train, y_train, cv=5, scoring=('accuracy','recall'), return_train_score=True)\r\n",
    "    #mod.fit(X_train, y_train)\r\n",
    "    #train_score = mod.score(X_train, y_train)\r\n",
    "    #test_score = mod.score(X_test, y_test)\r\n",
    "    return scores['train_accuracy'], scores['test_accuracy'], scores['train_recall'], scores['test_recall'], scores['fit_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gaussian NB test accuracy is: 0.6413\n",
      "The Categorical NB test accuracy is: 0.5870\n",
      "The Multinomial NB test accuracy is: 0.6196\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\r\n",
    "gnb_train, gnb_test, gnb_y_pred = GNB(X_train, X_test, y_train, y_test)\r\n",
    "cnb_train, cnb_test, cnb_y_pred = CNB(X_train, X_test, y_train, y_test)\r\n",
    "mnb_train, mnb_test, mnb_y_pred = MNB(X_train, X_test, y_train, y_test)\r\n",
    "\r\n",
    "print(\"The Gaussian NB test accuracy is: %.4f\" % (gnb_test))\r\n",
    "print(\"The Categorical NB test accuracy is: %.4f\" % (cnb_test))\r\n",
    "print(\"The Multinomial NB test accuracy is: %.4f\" % (mnb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using poly kernel, the SVM test accuracy is: 0.6630\n"
     ]
    }
   ],
   "source": [
    "# SVM\r\n",
    "svm_train, svm_test, svm_y_pred = SVM(X_train, X_test, y_train, y_test, k='poly', c='balanced')\r\n",
    "print(\"Using poly kernel, the SVM test accuracy is: %.4f\" % (svm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy is: 0.6196\n",
      "AdaBoost accuracy is: 0.6087\n",
      "Gradient Boost accuracy is: 0.6458\n"
     ]
    }
   ],
   "source": [
    "# Boosting\r\n",
    "# XGBoost\r\n",
    "bo_pred = XGB(X_train, X_test, y_train, y_test)\r\n",
    "xgb_acc = accuracy_score(y_test, bo_pred)\r\n",
    "# AdaBoost\r\n",
    "pred, ada_acc = ada(X_train, X_test, y_train, y_test)\r\n",
    "# Gradient Boosting\r\n",
    "gb_train, gb_acc, train_recall, test_recall, time = gb(X_train, X_test, y_train, y_test)\r\n",
    "\r\n",
    "print(\"XGBoost accuracy is: %.4f\" % (xgb_acc))\r\n",
    "print(\"AdaBoost accuracy is: %.4f\" % (ada_acc))\r\n",
    "print(\"Gradient Boosting accuracy is: %.4f\" % (np.average(gb_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters:  {'learning_rate': 0.2, 'n_estimators': 50}\n",
      "The best test accuracy is: 0.6413\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model Selection\r\n",
    "param_gird = {'n_estimators':[10,50,100,150],'learning_rate':[0.1,0.2,0.5,0.7,1.0]}\r\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\r\n",
    "gbcv = GridSearchCV(gb_model, param_gird, cv=5, scoring=('accuracy', 'recall'), refit='accuracy', return_train_score=True)\r\n",
    "gbcv.fit(X_train, y_train)\r\n",
    "y_pred = gbcv.best_estimator_.predict(X_test)\r\n",
    "acc = accuracy_score(y_test, y_pred)\r\n",
    "print(\"The best parameters: \", gbcv.best_params_)\r\n",
    "print(\"The best test accuracy is: %.4f\" % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f34899018329e63e2cbdc2102f39aed28d25ef71d36d5772a11311ac227d0afb"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}